import os
import pandas as pd
import streamlit as st

def PL_road(uploaded_files):
    dataframes = {}
    total_files = len(uploaded_files)  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç·æ•°
    progress_bar = st.progress(0)  # é€²æ—ãƒãƒ¼ã‚’0%ã§åˆæœŸåŒ–

    for i, uploaded_file in enumerate(uploaded_files):
        file_name = uploaded_file.name
        df = pd.read_excel(uploaded_file, header=6)  # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰DataFrameã‚’èª­ã¿è¾¼ã‚€
        dataframes[file_name] = df
        progress_bar.progress((i + 1) / total_files)  # é€²æ—ãƒãƒ¼ã‚’æ›´æ–°

    progress_bar.empty()  # å‡¦ç†çµ‚äº†å¾Œã«é€²æ—ãƒãƒ¼ã‚’éè¡¨ç¤ºã«ã™ã‚‹
    print('PLãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚ŠãŒå®Œäº†')
    return dataframes

def initialize_output_dataframes(dataframes):
    columns_op =[
        "æœˆç¨®åˆ¥","ç¨®é¡","å½¢å¼","ä½œæˆæ–¹æ³•","ä»˜ç®‹","ä¼ç¥¨æ—¥ä»˜","ä¼ç¥¨ç•ªå·","ä¼ç¥¨æ‘˜è¦","æç•ª","å€Ÿæ–¹éƒ¨é–€","å€Ÿæ–¹éƒ¨é–€å","å€Ÿæ–¹ç§‘ç›®","å€Ÿæ–¹ç§‘ç›®å","å€Ÿæ–¹è£œåŠ©","å€Ÿæ–¹è£œåŠ©ç§‘ç›®å","å€Ÿæ–¹é‡‘é¡","å€Ÿæ–¹æ¶ˆè²»ç¨ã‚³ãƒ¼ãƒ‰","å€Ÿæ–¹æ¶ˆè²»ç¨æ¥­ç¨®","å€Ÿæ–¹æ¶ˆè²»ç¨ç¨ç‡",
        "å€Ÿæ–¹è³‡é‡‘åŒºåˆ†","å€Ÿæ–¹ä»»æ„é …ç›®ï¼‘","å€Ÿæ–¹ä»»æ„é …ç›®ï¼’","å€Ÿæ–¹ã‚¤ãƒ³ãƒœã‚¤ã‚¹æƒ…å ±","è²¸æ–¹éƒ¨é–€","è²¸æ–¹éƒ¨é–€å","è²¸æ–¹ç§‘ç›®","è²¸æ–¹ç§‘ç›®å","è²¸æ–¹è£œåŠ©","è²¸æ–¹è£œåŠ©ç§‘ç›®å","è²¸æ–¹é‡‘é¡","è²¸æ–¹æ¶ˆè²»ç¨ã‚³ãƒ¼ãƒ‰","è²¸æ–¹æ¶ˆè²»ç¨æ¥­ç¨®","è²¸æ–¹æ¶ˆè²»ç¨ç¨ç‡",
        "è²¸æ–¹è³‡é‡‘åŒºåˆ†","è²¸æ–¹ä»»æ„é …ç›®ï¼‘","è²¸æ–¹ä»»æ„é …ç›®ï¼’","è²¸æ–¹ã‚¤ãƒ³ãƒœã‚¤ã‚¹æƒ…å ±","æ‘˜è¦","æœŸæ—¥","è¨¼ç•ªå·","å…¥åŠ›ãƒã‚·ãƒ³","å…¥åŠ›ãƒ¦ãƒ¼ã‚¶","å…¥åŠ›ã‚¢ãƒ—ãƒª","å…¥åŠ›ä¼šç¤¾","å…¥åŠ›æ—¥ä»˜"
    ] 
    # æ–°ã—ã„DataFrameã‚’æ ¼ç´ã™ã‚‹è¾æ›¸
    output_dataframes = {}

    # dataframes è¾æ›¸å†…ã®å„åº—èˆ—DataFrameã«å¯¾ã—ã¦å‡¦ç†ã‚’å®Ÿè¡Œ
    for store_code, df in tqdm(dataframes.items(), desc="åº—èˆ—ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­..."):
        new_df = pd.DataFrame(columns=columns_op, index=range(27), data=np.nan)
        
        # æ–°ã—ã„DataFrameã‚’è¾æ›¸ã«æ ¼ç´
        output_dataframes[f"{store_code}_output"] = new_df

    print('å‡ºåŠ›ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆå®Œäº†ğŸ‰')
    return output_dataframes

def mapping_preparing(dataframes_with , output_dataframes):
    for key, withdraw_df in tqdm(dataframes_with.items(), desc="ãƒ‡ãƒ¼ã‚¿è»¢è¨˜å‰ã®æº–å‚™ä¸­..."):
        output_key = f"{key}_output"
        if output_key in output_dataframes:
            output_df = output_dataframes[output_key]

            # NaNè¡Œã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            output_df.dropna(how='all', inplace=True)

            # è»¢è¨˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®æ•°ã«åŸºã¥ã„ã¦è¡Œã‚’è¿½åŠ 
            needed_rows = len(withdraw_df)
            current_rows = len(output_df)
            additional_rows = needed_rows - (current_rows - output_df.last_valid_index() - 1)

            if additional_rows > 0:
                new_rows = pd.DataFrame(np.nan, index=range(additional_rows), columns=output_df.columns)
                output_df = pd.concat([output_df, new_rows], ignore_index=True)
            
            output_dataframes[output_key] = output_df  # æ›´æ–°ã•ã‚ŒãŸDataFrameã‚’å†æ ¼ç´

        print('è¡Œè¿½åŠ å®Œäº†ğŸŒŸ')